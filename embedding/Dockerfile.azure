# SPDX-License-Identifier: MIT
# Copyright (c) 2025 Copilot-for-Consensus contributors

# Azure-optimized Dockerfile for embedding service
# Excludes PyTorch and local models, uses Azure OpenAI Embeddings API
FROM python:3.14-slim@sha256:1f741aef81d09464251f4c52c83a02f93ece0a636db125d411bd827bf381a763

WORKDIR /app

# Install shared adapters in dependency order using centralized script
# Use BuildKit cache mount for pip cache to speed up rebuilds
COPY adapters/ /app/adapters/
RUN --mount=type=cache,target=/root/.cache/pip \
    python /app/adapters/scripts/install_adapters.py \
    copilot_embedding \
    copilot_auth \
    copilot_config \
    copilot_message_bus \
    copilot_event_retry \
    copilot_storage \
    copilot_vectorstore \
    copilot_metrics \
    copilot_error_reporting \
    copilot_schema_validation \
    copilot_logging \
    copilot_secrets \
    copilot_startup

# Install Azure-specific vectorstore backend (Qdrant and Azure AI Search)
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -e /app/adapters/copilot_vectorstore[qdrant,azure]

# Install Azure OpenAI embedding backend only (excludes PyTorch and local models)
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -e /app/adapters/copilot_embedding[openai]

# Copy schema files for validation
COPY docs/schemas /app/docs/schemas

# Install service dependencies with cache mount
COPY embedding/requirements.txt .
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -r requirements.txt

# Copy service code (last to maximize cache reuse)
COPY embedding/*.py ./
COPY embedding/app/ ./app/

CMD ["python", "main.py"]
