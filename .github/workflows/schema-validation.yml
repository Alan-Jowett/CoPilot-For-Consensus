# SPDX-License-Identifier: MIT
# Copyright (c) 2025 Copilot-for-Consensus contributors

name: Schema Validation

on:
  push:
    branches: [ main ]
    paths:
      - 'docs/schemas/configs/**'
      - 'adapters/copilot_config/**'
      - '.github/workflows/schema-validation.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'docs/schemas/configs/**'
      - 'adapters/copilot_config/**'
      - '.github/workflows/schema-validation.yml'
  workflow_dispatch:  # Allow manual triggering

permissions:
  contents: read
  checks: write
  pull-requests: write

concurrency:
  # Cancel any in-progress instance of this workflow for the same PR.
  # Allow running concurrently with any commits on any other branch.
  group: schema-validation-${{ github.event.pull_request.number || github.sha || github.ref }}
  cancel-in-progress: true

jobs:
  validate-schemas:
    name: Validate Configuration Schemas
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          fetch-depth: 0  # Fetch full history for comparison

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install jsonschema
          cd adapters/copilot_config
          pip install -e .

      - name: Validate schema JSON syntax
        run: |
          echo "Validating JSON syntax for all config schemas..."
          python - <<'PYTHON_VALIDATE_JSON'
          import glob
          import json
          import sys

          errors = []
          for schema_path in glob.glob('docs/schemas/configs/services/*.json'):
              print(f"Validating {schema_path}...")
              try:
                  with open(schema_path, 'r', encoding='utf-8') as f:
                      json.load(f)
              except Exception as exc:
                  print(f"ERROR: Failed to parse {schema_path}: {exc}")
                  errors.append(schema_path)

          if errors:
              sys.exit(1)

          print("✓ All schemas have valid JSON syntax")
          PYTHON_VALIDATE_JSON

      - name: Check schema version fields
        run: |
          echo "Checking that all schemas have version fields..."
          python - <<'PYTHON_SCRIPT'
          import json
          import sys
          import glob

          errors = []
          for schema_file in glob.glob('docs/schemas/configs/services/*.json'):
              print(f"Checking {schema_file}...")
              try:
                  with open(schema_file, encoding='utf-8') as f:
                      schema = json.load(f)
                  if 'schema_version' not in schema:
                      errors.append(f'ERROR: Missing schema_version in {schema_file}')
                  if 'min_service_version' not in schema:
                      errors.append(f'ERROR: Missing min_service_version in {schema_file}')
                  if 'schema_version' in schema and 'min_service_version' in schema:
                      print(f'✓ {schema_file} has version fields')
              except Exception as e:
                  print(f'ERROR: Failed to check {schema_file}: {e}')
                  sys.exit(1)

          if errors:
              for error in errors:
                  print(error)
              sys.exit(1)

          print("✓ All schemas have required version fields")
          PYTHON_SCRIPT

      - name: Check for breaking changes in modified schemas
        if: github.event_name == 'pull_request'
        run: |
          echo "Checking for breaking changes in modified schemas..."

          # Get list of modified schema files
          modified_schemas=$(git diff --name-only origin/${{ github.base_ref }}...HEAD | grep 'docs/schemas/configs/.*\.json$' || true)

          if [ -z "$modified_schemas" ]; then
            echo "No schema files changed"
            exit 0
          fi

          for schema in $modified_schemas; do
            if [ -f "$schema" ]; then
              echo "Checking compatibility for $schema..."

              # Get the old version from base branch
              if git show origin/${{ github.base_ref }}:"$schema" > /tmp/old_schema.json 2>/dev/null; then
                # Basic compatibility check (inline Python)
                python - "$schema" <<'PYTHON_COMPAT_CHECK'
          import json
          import sys

          new_schema_path = sys.argv[1]

          with open('/tmp/old_schema.json', 'r') as f:
              old = json.load(f)
          with open(new_schema_path, 'r') as f:
              new = json.load(f)

          breaking_changes = []

          # Check for removed required fields (breaking change)
          if 'required' in old and 'required' in new:
              removed_required = set(old.get('required', [])) - set(new.get('required', []))
              if removed_required:
                  breaking_changes.append(f"Removed required fields: {removed_required}")

          # Check for added required fields (breaking change - forces config updates)
          if 'required' in old and 'required' in new:
              added_required = set(new.get('required', [])) - set(old.get('required', []))
              if added_required:
                  breaking_changes.append(f"Added required fields: {added_required}")

          # Check for removed enum values (breaking change for discriminants)
          if 'properties' in old and 'discriminant' in old['properties']:
              old_enum = set(old['properties']['discriminant'].get('enum', []))
              if 'properties' in new and 'discriminant' in new['properties']:
                  new_enum = set(new['properties']['discriminant'].get('enum', []))
                  removed_enum = old_enum - new_enum
                  if removed_enum:
                      breaking_changes.append(f"Removed discriminant values: {removed_enum}")

          # Check for type changes in properties (breaking change)
          def check_type_changes(old_props, new_props, path=""):
              if not isinstance(old_props, dict) or not isinstance(new_props, dict):
                  return
              for prop_name in old_props.keys():
                  if prop_name in new_props:
                      old_prop = old_props[prop_name]
                      new_prop = new_props[prop_name]
                      prop_path = f"{path}.{prop_name}" if path else prop_name
                      
                      # Check type changes
                      if 'type' in old_prop and 'type' in new_prop:
                          if old_prop['type'] != new_prop['type']:
                              breaking_changes.append(f"Type changed for '{prop_path}': {old_prop['type']} -> {new_prop['type']}")
                      
                      # Check constraint changes (pattern, minLength, maxLength, minimum, maximum)
                      constraints = ['pattern', 'minLength', 'maxLength', 'minimum', 'maximum', 'minItems', 'maxItems']
                      for constraint in constraints:
                          if constraint in old_prop and constraint in new_prop:
                              if old_prop[constraint] != new_prop[constraint]:
                                  breaking_changes.append(f"Constraint '{constraint}' changed for '{prop_path}': {old_prop[constraint]} -> {new_prop[constraint]}")
                          elif constraint in old_prop and constraint not in new_prop:
                              # Removing a constraint could be breaking if it was restrictive
                              pass  # Generally safe, loosens restrictions
                          elif constraint not in old_prop and constraint in new_prop:
                              # Adding a constraint is breaking if it restricts previously valid values
                              breaking_changes.append(f"New constraint '{constraint}' added for '{prop_path}': {new_prop[constraint]}")
                      
                      # Recursively check nested properties
                      if 'properties' in old_prop and 'properties' in new_prop:
                          check_type_changes(old_prop['properties'], new_prop['properties'], prop_path)

          if 'properties' in old and 'properties' in new:
              check_type_changes(old['properties'], new['properties'])

          if breaking_changes:
              print("❌ Breaking changes detected:")
              for change in breaking_changes:
                  print(f"  - {change}")
              sys.exit(1)

          print("✓ No breaking changes detected")
          PYTHON_COMPAT_CHECK

                if [ $? -ne 0 ]; then
                  echo "❌ Compatibility check failed for $schema"
                  exit 1
                fi
                echo "✓ No breaking changes detected in $schema"
              else
                echo "New schema file detected: $schema (skipping compatibility check)"
              fi
            fi
          done

          echo "✓ All schema changes are compatible"

      - name: Validate schema against JSON Schema draft
        run: |
          echo "Validating schemas against JSON Schema draft..."
          python -c "
          import json
          import sys
          from jsonschema import Draft202012Validator, ValidationError

          errors = []
          for schema_file in [
              'docs/schemas/configs/services/auth.json',
              'docs/schemas/configs/services/chunking.json',
              'docs/schemas/configs/services/embedding.json',
              'docs/schemas/configs/services/ingestion.json',
              'docs/schemas/configs/services/orchestrator.json',
              'docs/schemas/configs/services/parsing.json',
              'docs/schemas/configs/services/reporting.json',
              'docs/schemas/configs/services/summarization.json',
          ]:
              try:
                  with open(schema_file, 'r') as f:
                      schema = json.load(f)

                  # Check that schema has required top-level fields
                  if 'service_name' not in schema:
                      errors.append(f'{schema_file}: Missing service_name')
                  if 'service_settings' not in schema:
                      errors.append(f'{schema_file}: Missing service_settings')

                  print(f'✓ {schema_file} is valid')
              except Exception as e:
                  errors.append(f'{schema_file}: {e}')

          if errors:
              print('\\n❌ Schema validation errors:')
              for error in errors:
                  print(f'  - {error}')
              sys.exit(1)

          print('\\n✓ All schemas are valid')
          "

      - name: Summary
        if: always()
        run: |
          echo "Schema validation complete"
          echo "- JSON syntax validation"
          echo "- Version field validation"
          echo "- Compatibility checking"
          echo "- JSON Schema draft validation"
