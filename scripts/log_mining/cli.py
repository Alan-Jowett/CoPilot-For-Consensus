# SPDX-License-Identifier: MIT
# Copyright (c) 2025 Copilot-for-Consensus contributors

"""CLI for mining log templates and sampling anomalies.

Designed to work with:
- docker compose logs (prefixed `service | ...`)
- Azure Log Analytics exports (JSON arrays / JSON lines)

Primary goals:
- Normalize obvious variables (timestamps, GUIDs, IPs, IDs)
- Mine templates using Drain3
- Provide sampling strategies that preserve rare/unusual log types
"""

from __future__ import annotations

import argparse
import json
import sys
from pathlib import Path

from .mining import (
    MiningConfig,
    mine_logs,
    write_report_json,
)
from .reporting import load_report_json, write_report_markdown_from_report


def _existing_path(value: str) -> Path:
    p = Path(value)
    if not p.exists():
        raise argparse.ArgumentTypeError(f"Path does not exist: {value}")
    return p


def _parse_fields_csv(value: str) -> list[str]:
    value = value.strip()
    if not value:
        return []
    return [part.strip() for part in value.split(",") if part.strip()]


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        prog="log_mining",
        description=(
            "Cluster/minimize logs via Drain3 template mining, then sample "
            "rare/interesting cases for anomaly hunting."
        ),
    )

    parser.add_argument(
        "--input",
        "-i",
        type=_existing_path,
        help="Input file path. If omitted, reads from stdin.",
    )
    parser.add_argument(
        "--output",
        "-o",
        type=Path,
        default=Path("log_mining_report.json"),
        help="Output report path (JSON). Default: ./log_mining_report.json",
    )

    parser.add_argument(
        "--output-markdown",
        type=Path,
        default=None,
        help=(
            "Optional Markdown output path for a human-readable summary (focused on warnings/errors). "
            "If omitted, no Markdown is generated."
        ),
    )

    parser.add_argument(
        "--input-is-report",
        action="store_true",
        help=(
            "Treat --input as an existing JSON report (generated by this tool) and only render Markdown."
        ),
    )

    parser.add_argument(
        "--focus-levels",
        default="ERROR,WARNING",
        help="Comma-separated levels to include in Markdown focus view. Default: ERROR,WARNING",
    )

    parser.add_argument(
        "--md-top",
        type=int,
        default=30,
        help="How many top focused templates to show in Markdown. Default: 30",
    )

    parser.add_argument(
        "--md-per-service",
        type=int,
        default=10,
        help="How many focused templates per service to show in Markdown. Default: 10",
    )

    parser.add_argument(
        "--md-samples",
        type=int,
        default=1,
        help="How many samples to include per template in Markdown. Default: 1",
    )

    parser.add_argument(
        "--md-include-keywords",
        action="store_true",
        default=True,
        help=(
            "Also include templates that match error-like keywords (for logs without level=...). "
            "Enabled by default."
        ),
    )

    parser.add_argument(
        "--md-no-keywords",
        action="store_true",
        help="Disable keyword-based inclusion for Markdown focus view (levels only).",
    )

    parser.add_argument(
        "--format",
        choices=["auto", "plain", "docker", "azure-console", "azure-law"],
        default="auto",
        help=(
            "Input format. 'docker' expects `service | payload`. "
            "'azure-console' expects an Azure export JSON array/lines with Log_s. "
            "'azure-law' expects an Azure Log Analytics query JSON payload with tables/rows. "
            "'plain' treats each line as a log message." 
        ),
    )

    parser.add_argument(
        "--group-by",
        choices=["none", "service"],
        default="service",
        help="Whether to mine templates per service/container name.",
    )

    parser.add_argument(
        "--extract-json-field",
        default="message",
        help=(
            "If a payload is JSON, extract this field as the message for mining. "
            "Default: message"
        ),
    )

    parser.add_argument(
        "--include-fields",
        type=_parse_fields_csv,
        default=["level", "logger"],
        help=(
            "Comma-separated JSON fields (from payload) to prefix into the mined text. "
            "Default: level,logger"
        ),
    )

    parser.add_argument(
        "--max-lines",
        type=int,
        default=0,
        help="Optional cap on processed lines (0 = unlimited).",
    )

    parser.add_argument(
        "--per-template-samples",
        type=int,
        default=3,
        help="How many example raw lines to keep per template.",
    )

    parser.add_argument(
        "--rare-template-threshold",
        type=int,
        default=5,
        help="Templates with count <= this value are flagged as rare/anomalous.",
    )

    parser.add_argument(
        "--drain3-config",
        type=_existing_path,
        default=Path(__file__).with_name("drain3.ini"),
        help="Path to drain3.ini. Default: scripts/log_mining/drain3.ini",
    )

    parser.add_argument(
        "--emit-top",
        type=int,
        default=50,
        help="How many top templates to include in the report summary.",
    )

    parser.add_argument(
        "--emit-rare",
        type=int,
        default=200,
        help="How many rare templates to include in the report.",
    )

    return parser


def main(argv: list[str] | None = None) -> int:
    args = build_parser().parse_args(argv)

    focus_levels = [p.strip() for p in str(args.focus_levels).split(",") if p.strip()]
    include_keywords = bool(args.md_include_keywords) and (not bool(args.md_no_keywords))

    if args.input_is_report:
        if args.input is None:
            raise SystemExit("--input-is-report requires --input")
        if args.output_markdown is None:
            raise SystemExit("--input-is-report requires --output-markdown")

        report = load_report_json(Path(args.input))
        write_report_markdown_from_report(
            report,
            Path(args.output_markdown),
            focus_levels=focus_levels,
            include_keywords=include_keywords,
            top_n=args.md_top,
            per_service_n=args.md_per_service,
            rare_threshold=args.rare_template_threshold,
            max_samples_per_template=args.md_samples,
        )

        print(
            json.dumps(
                {
                    "output_markdown": str(args.output_markdown),
                    "focus_levels": focus_levels,
                },
                indent=2,
            )
        )
        return 0

    cfg = MiningConfig(
        input_format=args.format,
        group_by=args.group_by,
        extract_json_field=args.extract_json_field,
        include_fields=args.include_fields,
        max_lines=args.max_lines,
        per_template_samples=args.per_template_samples,
        rare_template_threshold=args.rare_template_threshold,
        drain3_config_path=Path(args.drain3_config),
        emit_top=args.emit_top,
        emit_rare=args.emit_rare,
    )

    if args.input is None:
        # stdin mode
        result = mine_logs(sys_stdin=True, input_path=None, config=cfg)
    else:
        result = mine_logs(sys_stdin=False, input_path=Path(args.input), config=cfg)

    write_report_json(result, args.output)

    if args.output_markdown is not None:
        report = load_report_json(Path(args.output))
        write_report_markdown_from_report(
            report,
            Path(args.output_markdown),
            focus_levels=focus_levels,
            include_keywords=include_keywords,
            top_n=args.md_top,
            per_service_n=args.md_per_service,
            rare_threshold=args.rare_template_threshold,
            max_samples_per_template=args.md_samples,
        )

    print(
        json.dumps(
            {
                "output": str(args.output),
                "output_markdown": str(args.output_markdown) if args.output_markdown else None,
                "lines_total": result.meta.lines_total,
                "lines_parsed": result.meta.lines_parsed,
                "templates_total": result.meta.templates_total,
                "services": result.meta.services,
            },
            indent=2,
        )
    )

    return 0
