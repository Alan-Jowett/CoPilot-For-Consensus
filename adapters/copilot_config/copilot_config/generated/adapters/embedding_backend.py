# SPDX-License-Identifier: MIT
# Copyright (c) 2025 Copilot-for-Consensus contributors

"""Generated typed configuration for embedding_backend adapter.

DO NOT EDIT THIS FILE MANUALLY.
This file is auto-generated from JSON schemas by scripts/generate_typed_configs.py.
"""

from dataclasses import dataclass
from typing import Literal


@dataclass
class DriverConfig_EmbeddingBackend_AzureOpenai:
    """Configuration for embedding_backend adapter using azure_openai driver."""
    api_base: str | None = None
    """Azure OpenAI endpoint URL"""
    api_key: str | None = None
    # Azure OpenAI API key
    api_version: str | None = '2024-02-15-preview'
    # Azure OpenAI API version
    deployment_name: str | None = None
    # Azure OpenAI deployment name for embeddings
    model: str | None = None
    # Optional model name to map to deployment


@dataclass
class DriverConfig_EmbeddingBackend_Huggingface:
    """Configuration for embedding_backend adapter using huggingface driver."""
    cache_dir: str | None = None
    """Cache directory for model files"""
    device: str | None = None
    # Device to use (cpu, cuda, mps)
    max_length: int | None = 512
    # Maximum sequence length for tokenization
    model_name: str | None = None
    # HuggingFace model name (e.g., 'sentence-transformers/all-MiniLM-L6-v2')


@dataclass
class DriverConfig_EmbeddingBackend_Mock:
    """Configuration for embedding_backend adapter using mock driver."""
    dimension: int | None = 384
    """Embedding dimension for mock backend"""


@dataclass
class DriverConfig_EmbeddingBackend_Openai:
    """Configuration for embedding_backend adapter using openai driver."""
    api_key: str | None = None
    """OpenAI API key"""
    model: str | None = None
    # OpenAI embedding model name
    organization: str | None = None
    # Optional OpenAI organization id


@dataclass
class DriverConfig_EmbeddingBackend_Sentencetransformers:
    """Configuration for embedding_backend adapter using sentencetransformers driver."""
    cache_dir: str | None = None
    """Cache folder for model files"""
    device: str | None = 'cpu'
    # Device to use (cpu, cuda, mps)
    model_name: str | None = 'all-MiniLM-L6-v2'
    # SentenceTransformers model name to use


@dataclass
class AdapterConfig_EmbeddingBackend:
    """Configuration for embedding_backend adapter."""
    embedding_backend_type: Literal["azure_openai", "huggingface", "mock", "openai", "sentencetransformers"]
    driver: (
        DriverConfig_EmbeddingBackend_AzureOpenai |
        DriverConfig_EmbeddingBackend_Huggingface |
        DriverConfig_EmbeddingBackend_Mock |
        DriverConfig_EmbeddingBackend_Openai |
        DriverConfig_EmbeddingBackend_Sentencetransformers
    )
